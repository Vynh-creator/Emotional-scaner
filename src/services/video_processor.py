import sys
import cv2
import time
import numpy as np
import sounddevice as sd
import asyncio
from PyQt6.QtWidgets import (QApplication, QWidget, QVBoxLayout,
                             QPushButton, QLabel, QSpinBox, QHBoxLayout, QTextEdit)
from PyQt6.QtCore import Qt, QTimer
from PyQt6.QtGui import QImage, QPixmap
from threading import Thread, Lock


class VideoRecorder(QWidget):
    def __init__(self, camera_idx=0, sample_rate=44100):
        super().__init__()
        self.camera_idx = camera_idx
        self.sample_rate = sample_rate
        self.cap = None
        
        self.video_buffer = []
        self.audio_buffer = []
        self.last_saved_video_chunk = []
        self.last_saved_audio_chunk = []
        self.is_recording = False
        self.buffer_lock = Lock()
        
        self.audio_stream = None
        self.chunk_timer = None

        self.init_ui()
        self.init_camera()
        
        # –¢–∞–π–º–µ—Ä –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤
        self.frame_timer = QTimer()
        self.frame_timer.timeout.connect(self.update_frame)
        self.frame_timer.start(30)  # ~30 FPS

    def init_camera(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã"""
        self.cap = cv2.VideoCapture(self.camera_idx)
        if not self.cap.isOpened():
            self.preview_label.setText("‚ùå –û—à–∏–±–∫–∞: –ö–∞–º–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    def init_ui(self):
        self.setWindowTitle("Emotion Analysis & Recorder")
        self.setMinimumWidth(700)
        layout = QVBoxLayout()

        self.preview_label = QLabel("–û–∂–∏–¥–∞–Ω–∏–µ –ø–æ—Ç–æ–∫–∞...")
        self.preview_label.setFixedSize(640, 480)
        self.preview_label.setStyleSheet("background: black; border: 2px solid #333;")
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(self.preview_label)

        self.info_label = QLabel("–°—Ç–∞—Ç—É—Å: –ì–æ—Ç–æ–≤")
        layout.addWidget(self.info_label)

        layout.addWidget(QLabel("–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (DeepSeek):"))
        self.ai_log = QTextEdit()
        self.ai_log.setReadOnly(True)
        self.ai_log.setMaximumHeight(150)
        self.ai_log.setPlaceholderText("–ó–¥–µ—Å—å –ø–æ—è–≤—è—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞...")
        self.ai_log.setStyleSheet("background: #1e1e1e; color: #00ff00; font-family: Consolas;")
        layout.addWidget(self.ai_log)

        controls = QHBoxLayout()
        controls.addWidget(QLabel("–ò–Ω—Ç–µ—Ä–≤–∞–ª –∑–∞—Ö–≤–∞—Ç–∞ (—Å–µ–∫):"))
        self.interval_spin = QSpinBox()
        self.interval_spin.setRange(1, 10)
        self.interval_spin.setValue(3)
        controls.addWidget(self.interval_spin)
        layout.addLayout(controls)

        self.btn_toggle = QPushButton("üî¥ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å")
        self.btn_toggle.clicked.connect(self.toggle_recording)
        layout.addWidget(self.btn_toggle)

        self.btn_play = QPushButton("‚ñ∂Ô∏è –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç")
        self.btn_play.clicked.connect(self.play_last_chunk)
        layout.addWidget(self.btn_play)

        self.setLayout(layout)

    def update_frame(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–¥—Ä–∞ –≤ UI"""
        if self.cap and self.cap.isOpened():
            ret, frame = self.cap.read()
            if ret:
                if self.is_recording:
                    with self.buffer_lock:
                        self.video_buffer.append(frame.copy())
                
                self.update_ui_preview(frame)

    def audio_callback(self, indata, frames, time_info, status):
        """Callback –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ"""
        if status:
            print(f"Audio status: {status}")
        if self.is_recording:
            with self.buffer_lock:
                self.audio_buffer.append(indata.copy())

    def update_ui_preview(self, frame):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–¥—Ä–∞ –≤ –ø—Ä–µ–≤—å—é"""
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb.shape
        img = QImage(rgb.data, w, h, ch * w, QImage.Format.Format_RGB888)
        self.preview_label.setPixmap(
            QPixmap.fromImage(img).scaled(640, 480, Qt.AspectRatioMode.KeepAspectRatio)
        )

    def toggle_recording(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """–ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏"""
        self.is_recording = True
        with self.buffer_lock:
            self.video_buffer = []
            self.audio_buffer = []
        
        # –ó–∞–ø—É—Å–∫ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
        try:
            self.audio_stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=2,
                callback=self.audio_callback
            )
            self.audio_stream.start()
            audio_status = "‚úì"
        except Exception as e:
            print(f"Audio error: {e}")
            audio_status = "‚úó"
        
        self.btn_toggle.setText("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å")
        self.info_label.setText(f"–ó–∞–ø–∏—Å—å –∏–¥–µ—Ç... (–≤–∏–¥–µ–æ ‚úì | –∞—É–¥–∏–æ {audio_status})")
        self.ai_log.append(f"[{time.strftime('%H:%M:%S')}] –ù–∞—á–∞—Ç–∞ –∑–∞–ø–∏—Å—å")
        
        # –ó–∞–ø—É—Å–∫ —Ç–∞–π–º–µ—Ä–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤
        self.chunk_timer = QTimer()
        self.chunk_timer.timeout.connect(self.save_chunk)
        self.chunk_timer.start(self.interval_spin.value() * 1000)

    def stop_recording(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏"""
        self.is_recording = False
        
        if self.chunk_timer:
            self.chunk_timer.stop()
            self.chunk_timer = None
        
        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
            self.audio_stream = None
        
        self.btn_toggle.setText("üî¥ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å")
        self.info_label.setText("–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        self.ai_log.append(f"[{time.strftime('%H:%M:%S')}] –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

    def save_chunk(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞"""
        if not self.is_recording:
            return
        
        with self.buffer_lock:
            if self.video_buffer:
                self.last_saved_video_chunk = list(self.video_buffer)
                self.last_saved_audio_chunk = list(self.audio_buffer)
                
                video_frames = len(self.last_saved_video_chunk)
                audio_samples = sum(len(chunk) for chunk in self.last_saved_audio_chunk)
                
                self.video_buffer = []
                self.audio_buffer = []
                
                self.ai_log.append(
                    f"[{time.strftime('%H:%M:%S')}] –§—Ä–∞–≥–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: "
                    f"{video_frames} –∫–∞–¥—Ä–æ–≤, {audio_samples} –∞—É–¥–∏–æ —Å–µ–º–ø–ª–æ–≤"
                )

    def play_last_chunk(self):
        """–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞"""
        if not self.last_saved_video_chunk:
            self.info_label.setText("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—à–∏—Ç–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç!")
            return
        
        self.info_label.setText("‚ñ∂Ô∏è –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ...")
        
        # –ó–∞–ø—É—Å–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        Thread(target=self._play_video_and_audio, daemon=True).start()

    def _play_video_and_audio(self):
        """–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ"""
        # –ó–∞–ø—É—Å–∫ –∞—É–¥–∏–æ –≤ —Ñ–æ–Ω–µ
        audio_thread = None
        if self.last_saved_audio_chunk:
            audio_thread = Thread(target=self._play_audio, daemon=True)
            audio_thread.start()
        
        # –ü–æ–∫–∞–∑ –≤–∏–¥–µ–æ
        cv2.namedWindow("Playback", cv2.WINDOW_NORMAL)
        for frame in self.last_saved_video_chunk:
            cv2.imshow("Playback", frame)
            if cv2.waitKey(30) & 0xFF == ord('q'):
                break
        cv2.destroyWindow("Playback")
        
        if audio_thread:
            audio_thread.join()

    def _play_audio(self):
        """–í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ"""
        if self.last_saved_audio_chunk:
            audio_data = np.concatenate(self.last_saved_audio_chunk, axis=0)
            sd.play(audio_data, self.sample_rate)
            sd.wait()

    def closeEvent(self, event):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        self.is_recording = False
        
        if self.frame_timer:
            self.frame_timer.stop()
        
        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
        
        if self.cap and self.cap.isOpened():
            self.cap.release()
        
        cv2.destroyAllWindows()
        event.accept()


def get_working_camera_index():
    """–ü–æ–∏—Å–∫ —Ä–∞–±–æ—á–µ–π –∫–∞–º–µ—Ä—ã"""
    for idx in range(3):
        cap = cv2.VideoCapture(idx)
        if cap.isOpened():
            ret, frame = cap.read()
            cap.release()
            if ret and frame is not None:
                print(f"‚úì –ù–∞–π–¥–µ–Ω–∞ –∫–∞–º–µ—Ä–∞: {idx}")
                return idx
    
    print("‚ö† –ö–∞–º–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–¥–µ–∫—Å 0")
    return 0


async def main():
    app = QApplication(sys.argv)
    
    camera_idx = get_working_camera_index()
    window = VideoRecorder(camera_idx)
    window.show()
    
    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π Qt
    while True:
        app.processEvents()
        await asyncio.sleep(0.005)


try:
    asyncio.run(main())
except KeyboardInterrupt:
    pass
except RuntimeError as e:
    if "Event loop is closed" not in str(e):
        raise
